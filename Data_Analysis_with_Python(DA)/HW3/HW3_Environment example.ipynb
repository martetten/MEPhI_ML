{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XP0dsb-T3ORPYv4YQFV5j23PknFH06O6","timestamp":1732821653413}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":69,"metadata":{"id":"MXXTuy_o0sjk","executionInfo":{"status":"ok","timestamp":1732828499700,"user_tz":-180,"elapsed":4125,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"outputs":[],"source":["!pip install -q -U kaggle_environments"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import random\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from kaggle_environments import make, evaluate\n","import math"],"metadata":{"id":"yz23vWHD0wcj","executionInfo":{"status":"ok","timestamp":1732828505222,"user_tz":-180,"elapsed":245,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":["Опишем поведение агента, всегда играющего \"камень\" - это значение 0"],"metadata":{"id":"0kuo6IOxiRub"}},{"cell_type":"code","source":["%%writefile rock_agent.py\n","\n","#Example of the simple agent\n","#0 - rock\n","#1 - paper\n","#2 - scissors\n","def your_agent(observation, configuration):\n","    return 0"],"metadata":{"id":"bqTqV7B92rJ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732828508075,"user_tz":-180,"elapsed":231,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"9afbb385-1192-4e4f-9b2d-9ee07fa2674b"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting rock_agent.py\n"]}]},{"cell_type":"markdown","source":["Попробуем теперь использовать информацию о прошлых действиях противника. Опишем агента, который производит то же самое действие, что и оппонент на прошлом ходу"],"metadata":{"id":"et1J5hUGigeh"}},{"cell_type":"code","source":["%%writefile copy_opponent.py\n","\n","#Example\n","def copy_opponent(observation, configuration):\n","    #in case we have information about opponent last move\n","    if observation.step > 0:\n","        return observation.lastOpponentAction\n","    #initial step\n","    else:\n","        return random.randrange(0, configuration.signs)"],"metadata":{"id":"7l6Ttw6qi0jk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732828510652,"user_tz":-180,"elapsed":234,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"2c8572ab-bf31-44cc-ab2b-2f0e90339f78"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting copy_opponent.py\n"]}]},{"cell_type":"markdown","source":["Воспользуемся функцией evaluate из библиотеки kaggle_environments с помощью которой запустим наших агентов и проведем эксперимент на заданном количестве игр"],"metadata":{"id":"ExgIpXUVjbjN"}},{"cell_type":"code","source":["evaluate(\n","    \"rps\", #environment to use - no need to change\n","    [\"rock_agent.py\", \"copy_opponent.py\"], #agents to evaluate\n","    configuration={\"episodeSteps\": 100} #number of episodes\n",")"],"metadata":{"id":"wv6Ip6M004xa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732828512811,"user_tz":-180,"elapsed":236,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"6708fa6a-0dfc-4c05-8fae-f5de0057b1bc"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, None]]"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["evaluate(\n","    \"rps\", #environment to use - no need to change\n","    [\"rock_agent.py\", \"paper\"], #agents to evaluate\n","    configuration={\"episodeSteps\": 100} #number of episodes\n",")"],"metadata":{"id":"FC6_QWe9k3rr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732828514964,"user_tz":-180,"elapsed":451,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"56a42f8f-083a-4aa7-ec96-290f4a1b40ef"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[-99.0, 99.0]]"]},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["Из среды RPS Kaggle возьмем определение функции, вычисляющую победу агента (правый или левый)"],"metadata":{"id":"YwVm27SUU7X2"}},{"cell_type":"code","source":["def get_score(left_move, right_move):\n","    delta = (\n","        right_move - left_move\n","        if (left_move + right_move) % 2 == 0\n","        else left_move - right_move\n","    )\n","    return 0 if delta == 0 else math.copysign(1, delta)"],"metadata":{"id":"Skwti7VbU74u","executionInfo":{"status":"ok","timestamp":1732828852019,"user_tz":-180,"elapsed":219,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["1) Добавляем агента, который использует только камень"],"metadata":{"id":"35hBEp1nVVeJ"}},{"cell_type":"code","source":["def rock_only(observation, configuration):\n","    # Агент, который использует только камень\n","    return 0"],"metadata":{"id":"lrIIVYrgVt1l","executionInfo":{"status":"ok","timestamp":1732828853734,"user_tz":-180,"elapsed":246,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["2) Добавляем агента, который использует только бумагу"],"metadata":{"id":"Ii6PKMmYVzuZ"}},{"cell_type":"code","source":["def paper_only(observation, configuration):\n","    # Агент, который который использует только бумагу\n","    return 1"],"metadata":{"id":"qC3ioYQbVpaH","executionInfo":{"status":"ok","timestamp":1732828855253,"user_tz":-180,"elapsed":236,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":["3) Добавляем агента, который использует только ножницы"],"metadata":{"id":"Psgr9zyzV_Gc"}},{"cell_type":"code","source":["def scissors_only(observation, configuration):\n","    # Агент, который использует только ножницы\n","    return 2"],"metadata":{"id":"_wKa_-PyV-31","executionInfo":{"status":"ok","timestamp":1732828858637,"user_tz":-180,"elapsed":235,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":117,"outputs":[]},{"cell_type":"markdown","source":["4) Добавляем агента, чья стратегия - копировать предыдущий ход оппонента"],"metadata":{"id":"igth7o0LWHQH"}},{"cell_type":"code","source":["def copy_opponent(observation, configuration):\n","    # Агент, который копирует последний ход противника.\n","    if observation.step > 0:\n","        return observation.lastOpponentAction\n","    else:\n","        return random.randrange(0, configuration.signs)"],"metadata":{"id":"qa5C6A2rV7en","executionInfo":{"status":"ok","timestamp":1732828861032,"user_tz":-180,"elapsed":217,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":["5) Добавляем агента, чья стратегия - выбирать случайно"],"metadata":{"id":"ZtYJrKFQcGpE"}},{"cell_type":"code","source":["def random_only(observation, configuration):\n","    # Агент, который выбирает ход случайно (камень/бумага/ножницы)\n","    return random.choice([0, 1, 2])"],"metadata":{"id":"UyHyqvK2WXtE","executionInfo":{"status":"ok","timestamp":1732828863545,"user_tz":-180,"elapsed":219,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":119,"outputs":[]},{"cell_type":"markdown","source":["6) Добавляем агента, чья стратегия - выбрать выигрышное действие из предыдущего хода"],"metadata":{"id":"_4n1H_wycdIF"}},{"cell_type":"code","source":["def react_prev(observation, configuration):\n","    if observation.step == 0:\n","        # возвращаем рандомное значение из доступных вариантов\n","        return random.randrange(0, configuration.signs)\n","    # берем предыдущий ход соперника и ходим, чтобы победить его\n","    return (observation.lastOpponentAction + 1) % configuration.signs"],"metadata":{"id":"UVBGZ_VSdF0o","executionInfo":{"status":"ok","timestamp":1732828866041,"user_tz":-180,"elapsed":231,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":["7) Агент, который выбирает (камень/бумага/ножницы) по кругу (исходное положение определяется случайным образом)"],"metadata":{"id":"-QVFqB17ffO9"}},{"cell_type":"code","source":["def cycle_order(observation, configuration):\n","    # Агент, который выбирает ход по кругу (камень/бумага/ножницы)\n","    if observation.step == 0:\n","        # если это первый ход, выбираем случайное\n","        return random.randrange(0, configuration.signs)\n","    # иначе берем остаток от деления номера текущего эпизода на количество возможных вариантов\n","    return observation.step % configuration.signs"],"metadata":{"id":"xL4T_c3hfwIH","executionInfo":{"status":"ok","timestamp":1732828868400,"user_tz":-180,"elapsed":226,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"DO_beTG0O0mc"}},{"cell_type":"code","source":["def counter_react_prev(observation, configuration):\n","    global last_counter_action\n","    if observation.step == 0:\n","        last_counter_action = random.randrange(0, configuration.signs)\n","    elif get_score(last_counter_action, observation.lastOpponentAction) == 1:\n","        last_counter_action = (last_counter_action + 2) % configuration.signs\n","    else:\n","        last_counter_action = (observation.lastOpponentAction + 1) % configuration.signs\n","\n","    return last_counter_action"],"metadata":{"id":"fyGworDHO1GW","executionInfo":{"status":"ok","timestamp":1732828870739,"user_tz":-180,"elapsed":236,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":["8) Добавим агента, который побеждает циклического агента"],"metadata":{"id":"sQ81MvE2ppdk"}},{"cell_type":"code","source":["def counter_cycle_order(observation, configuration):\n","    # Агент, который выбирает ход, который бьет циклический ход противника.\n","    if observation.step == 0:\n","        return random.randrange(0, configuration.signs)\n","    else:\n","        return (observation.lastOpponentAction + 2) % configuration.signs"],"metadata":{"id":"YrvNyH950LjW","executionInfo":{"status":"ok","timestamp":1732828873094,"user_tz":-180,"elapsed":229,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":["9) Добавим агента, подсчитывающего наиболее частый ход оппонента, и реагирующего соответствующим образом"],"metadata":{"id":"_k8C00cqWFJ6"}},{"cell_type":"code","source":["def statistical(observation, configuration):\n","    # Агент, который подсчитывает наиболее частый ход оппонента\n","    # переменная для хранения статистики\n","    global action_histogram\n","    if observation.step == 0:\n","        action_histogram = {}\n","        return\n","    action = observation.lastOpponentAction\n","    if action not in action_histogram:\n","        action_histogram[action] = 0\n","    action_histogram[action] += 1\n","    mode_action = None\n","    mode_action_count = None\n","    for k, v in action_histogram.items():\n","        if mode_action_count is None or v > mode_action_count:\n","            mode_action = k\n","            mode_action_count = v\n","            continue\n","\n","    return (mode_action + 1) % configuration.signs"],"metadata":{"id":"M_eSHQf20dd9","executionInfo":{"status":"ok","timestamp":1732828875491,"user_tz":-180,"elapsed":230,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":124,"outputs":[]},{"cell_type":"markdown","source":["10) Добавим агента, котоырй выбирает ход, который бьет наиболее часто используемый противником ход"],"metadata":{"id":"3JJIT1ciWTUw"}},{"cell_type":"code","source":["def counter_stats(observation, configuration):\n","    # Агент, который выбирает ход, который бьет наиболее часто используемый противником ход\n","    if observation.get('step', 0) > 0:\n","        counts = [0, 0, 0]\n","        for action in observation.get('history', []):\n","            counts[action] += 1\n","        return (counts.index(max(counts)) + 1) % 3\n","    else:\n","        return random.choice([0, 1, 2])"],"metadata":{"id":"G9p8uSiZWGbN","executionInfo":{"status":"ok","timestamp":1732828877652,"user_tz":-180,"elapsed":226,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":["11) Адаптивный агент, который пытается предсказать следующий ход противника"],"metadata":{"id":"PoKNg_J1WY2E"}},{"cell_type":"code","source":["def adaptive(observation, configuration):\n","    # Адаптивный агент, который пытается предсказать следующий ход противника\n","    # Ход, который бьет предсказанный ход противника, или случайный ход, если история недостаточно длинная\n","    if observation.step > 1:\n","        if observation.get('lastOpponentAction', 0) == observation.get('history', [0, 0])[-2]:\n","            return (observation.get('lastOpponentAction', 0) + 1) % 3\n","        else:\n","            return random.randrange(0, configuration.signs)\n","    else:\n","        return random.randrange(0, configuration.signs)"],"metadata":{"id":"hP-1jlmrWZOi","executionInfo":{"status":"ok","timestamp":1732828879586,"user_tz":-180,"elapsed":215,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":["12) Добавим агента, стратегия которого - комбинация из стратегий 2х других агентов:\n","В первых 1/3 случаев - ходит как react_prev (выбрать выигрышное действие из предыдущего хода)\n","В дальнейшем - как statictical (выбирает ход, побеждающий наиболее частое действие соперника)"],"metadata":{"id":"eg4j_jH_WeKp"}},{"cell_type":"code","source":["def one_third(observation, configuration):\n","    # хранение послднего хода (т.к. переменная last_step занята, используем индекс 2)\n","    global last_step2\n","    # поле для хранения  количества повторов\n","    global repeats\n","    # переменная для хранения статистики\n","    global action_histogram2\n","\n","    if observation.step == 0:\n","        # если ход первый - сбрасываем статистику\n","        last_step2 = 0\n","        repeats = 0\n","        action_histogram2 = {}\n","\n","        # возвращаем случайное значение\n","        return random.randrange(0, configuration.signs)\n","    # сохраняем в переменную последний ход соперника\n","    action = observation.lastOpponentAction\n","    # если количество повторов меньше 1/3 от запланированного количества эпизодов\n","    if repeats < (configuration.get('episodeSteps') / 3):\n","        # увеличиваем счётчик повторов на 1\n","        repeats += 1\n","        # ходим с учётом предыдущего хода соперника\n","        return (action + 1) % configuration.signs\n","    # иначе (после прохождения 1/3 эпизодов)\n","    else:\n","        # если такого ключа еще нет в справочнике\n","        if action not in action_histogram2:\n","            # добавляем в справочник со значением 0\n","            action_histogram2[action] = 0\n","        # увеличиваем счётчик для такого хода соперника\n","        action_histogram2[action] += 1\n","        # определяем статистически самый частый ход соперника\n","        # инициализируем переменную для хранения хода с максимальным счетчиком\n","        mode_action = None\n","        # инициализируем переменную для хранения максимального значения счетчика\n","        mode_action_count = None\n","        # для каждой пары ключ-значение в справочнике статистики\n","        for k, v in action_histogram2.items():\n","            # если значение в справочнике для этого ключа не установлено\n","            # или значение итератора больше значения в справочнике\n","            if mode_action_count is None or v > mode_action_count:\n","                # сохраняем текущий ключ в переменную максимума\n","                mode_action = k\n","                # сохраняем текущее значение в переменную максимума\n","                mode_action_count = v\n","                # переходим к следующей итераци\n","                continue\n","        # ходим так, чтобы победить самый частый ход соперника\n","        return (mode_action + 1) % configuration.signs"],"metadata":{"id":"cSCFEpnwWajP","executionInfo":{"status":"ok","timestamp":1732829382564,"user_tz":-180,"elapsed":209,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":["Итоговый список агентов"],"metadata":{"id":"IkcPDUqeWiD9"}},{"cell_type":"code","source":["'''\n","agents = {\n","    'rock': rock_only,\n","    'paper': paper_only,\n","    'scissors': scissors_only,\n","    'copy': copy_opponent,\n","    'random': random_only,\n","    'react': react_prev,\n","    'cycle': cycle_order,\n","    'c_react': counter_react_prev,\n","    'c_cycle': counter_cycle_order,\n","    'stats': statistical,\n","    'c_stats': counter_stats,\n","    'adapt': adaptive,\n","    '1/3': one_third\n","}\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"GHh3HJZ8Wg5P","executionInfo":{"status":"ok","timestamp":1732829385118,"user_tz":-180,"elapsed":225,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"f075ae4d-082a-4474-cd8c-1815242abc20"},"execution_count":141,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nagents = {\\n    'rock': rock_only,\\n    'paper': paper_only,\\n    'scissors': scissors_only,\\n    'copy': copy_opponent,\\n    'random': random_only,\\n    'react': react_prev,\\n    'cycle': cycle_order,\\n    'c_react': counter_react_prev,\\n    'c_cycle': counter_cycle_order,\\n    'stats': statistical,\\n    'c_stats': counter_stats,\\n    'adapt': adaptive,\\n    '1/3': one_third\\n}\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":141}]},{"cell_type":"code","source":["agents = [\n","    rock_only,\n","    paper_only,\n","    scissors_only,\n","    copy_opponent,\n","    random_only,\n","    react_prev,\n","    cycle_order,\n","    counter_react_prev,\n","    counter_cycle_order,\n","    statistical,\n","    counter_stats,\n","    adaptive,\n","    one_third\n","]"],"metadata":{"id":"01h6z2Fzqic-","executionInfo":{"status":"ok","timestamp":1732829386876,"user_tz":-180,"elapsed":222,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}}},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"GpyWkB5zrIQk"}},{"cell_type":"code","source":["from kaggle_environments import make, evaluate\n","from collections import defaultdict\n","\n","# Запуск турнира\n","results = []\n","for i in range(len(agents)):\n","    for j in range(i + 1, len(agents)):\n","        agent1 = agents[i]\n","        agent2 = agents[j]\n","        match_result = evaluate(\n","            \"rps\",  # environment to use\n","            [agent1, agent2],  # agents to evaluate\n","            configuration={\"episodeSteps\": 100}  # number of episodes\n","        )\n","        results.append((agent1.__name__, agent2.__name__, match_result))\n","\n","# Вывод результатов\n","for result in results:\n","    print(f\"Agent 1: {result[0]}, Agent 2: {result[1]}, Result: {result[2]}\")\n","\n","# Подсчет результатов\n","agent_scores = defaultdict(lambda: {\"wins\": 0, \"losses\": 0, \"draws\": 0})\n","\n","for result in results:\n","    agent1_name = result[0]\n","    agent2_name = result[1]\n","    match_result = result[2][0]\n","\n","    # Проверка на корректность результатов\n","    if match_result[0] is None or match_result[1] is None:\n","        print(f\"Error in match between {agent1_name} and {agent2_name}: One of the agents returned None.\")\n","        continue\n","\n","    if match_result[0] > match_result[1]:\n","        agent_scores[agent1_name][\"wins\"] += 1\n","        agent_scores[agent2_name][\"losses\"] += 1\n","    elif match_result[0] < match_result[1]:\n","        agent_scores[agent1_name][\"losses\"] += 1\n","        agent_scores[agent2_name][\"wins\"] += 1\n","    else:\n","        agent_scores[agent1_name][\"draws\"] += 1\n","        agent_scores[agent2_name][\"draws\"] += 1\n","\n","# Вывод результатов\n","for agent, scores in agent_scores.items():\n","    print(f\"Agent: {agent}, Wins: {scores['wins']}, Losses: {scores['losses']}, Draws: {scores['draws']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YonbE2a9rFtp","executionInfo":{"status":"ok","timestamp":1732829411946,"user_tz":-180,"elapsed":22510,"user":{"displayName":"A Martynov","userId":"06661356698018382046"}},"outputId":"eee4d349-0f8f-4771-a4dd-12005f89ba15"},"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["Agent 1: rock_only, Agent 2: paper_only, Result: [[-99.0, 99.0]]\n","Agent 1: rock_only, Agent 2: scissors_only, Result: [[99.0, -99.0]]\n","Agent 1: rock_only, Agent 2: copy_opponent, Result: [[0, 0]]\n","Agent 1: rock_only, Agent 2: random_only, Result: [[0, 0]]\n","Agent 1: rock_only, Agent 2: react_prev, Result: [[-98.0, 98.0]]\n","Agent 1: rock_only, Agent 2: cycle_order, Result: [[0, 0]]\n","Agent 1: rock_only, Agent 2: counter_react_prev, Result: [[-49.0, 49.0]]\n","Agent 1: rock_only, Agent 2: counter_cycle_order, Result: [[98.0, -98.0]]\n","Agent 1: rock_only, Agent 2: statistical, Result: [[-98.0, 98.0]]\n","Agent 1: rock_only, Agent 2: counter_stats, Result: [[-97.0, 97.0]]\n","Agent 1: rock_only, Agent 2: adaptive, Result: [[-96.0, 96.0]]\n","Agent 1: rock_only, Agent 2: one_third, Result: [[-99.0, 99.0]]\n","Agent 1: paper_only, Agent 2: scissors_only, Result: [[-99.0, 99.0]]\n","Agent 1: paper_only, Agent 2: copy_opponent, Result: [[0, 0]]\n","Agent 1: paper_only, Agent 2: random_only, Result: [[0, 0]]\n","Agent 1: paper_only, Agent 2: react_prev, Result: [[-99.0, 99.0]]\n","Agent 1: paper_only, Agent 2: cycle_order, Result: [[0, 0]]\n","Agent 1: paper_only, Agent 2: counter_react_prev, Result: [[-50.0, 50.0]]\n","Agent 1: paper_only, Agent 2: counter_cycle_order, Result: [[98.0, -98.0]]\n","Agent 1: paper_only, Agent 2: statistical, Result: [[-97.0, 97.0]]\n","Agent 1: paper_only, Agent 2: counter_stats, Result: [[0, 0]]\n","Agent 1: paper_only, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: paper_only, Agent 2: one_third, Result: [[-97.0, 97.0]]\n","Agent 1: scissors_only, Agent 2: copy_opponent, Result: [[0, 0]]\n","Agent 1: scissors_only, Agent 2: random_only, Result: [[0, 0]]\n","Agent 1: scissors_only, Agent 2: react_prev, Result: [[-99.0, 99.0]]\n","Agent 1: scissors_only, Agent 2: cycle_order, Result: [[0, 0]]\n","Agent 1: scissors_only, Agent 2: counter_react_prev, Result: [[-50.0, 50.0]]\n","Agent 1: scissors_only, Agent 2: counter_cycle_order, Result: [[99.0, -99.0]]\n","Agent 1: scissors_only, Agent 2: statistical, Result: [[-99.0, 99.0]]\n","Agent 1: scissors_only, Agent 2: counter_stats, Result: [[97.0, -97.0]]\n","Agent 1: scissors_only, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: scissors_only, Agent 2: one_third, Result: [[-99.0, 99.0]]\n","Agent 1: copy_opponent, Agent 2: random_only, Result: [[0, 0]]\n","Agent 1: copy_opponent, Agent 2: react_prev, Result: [[-50.0, 50.0]]\n","Agent 1: copy_opponent, Agent 2: cycle_order, Result: [[-97.0, 97.0]]\n","Agent 1: copy_opponent, Agent 2: counter_react_prev, Result: [[96.0, -96.0]]\n","Agent 1: copy_opponent, Agent 2: counter_cycle_order, Result: [[50.0, -50.0]]\n","Agent 1: copy_opponent, Agent 2: statistical, Result: [[-20.0, 20.0]]\n","Agent 1: copy_opponent, Agent 2: counter_stats, Result: [[0, 0]]\n","Agent 1: copy_opponent, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: copy_opponent, Agent 2: one_third, Result: [[-30.0, 30.0]]\n","Agent 1: random_only, Agent 2: react_prev, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: cycle_order, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: counter_react_prev, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: counter_cycle_order, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: statistical, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: counter_stats, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: random_only, Agent 2: one_third, Result: [[0, 0]]\n","Agent 1: react_prev, Agent 2: cycle_order, Result: [[0, 0]]\n","Agent 1: react_prev, Agent 2: counter_react_prev, Result: [[0, 0]]\n","Agent 1: react_prev, Agent 2: counter_cycle_order, Result: [[99.0, -99.0]]\n","Agent 1: react_prev, Agent 2: statistical, Result: [[59.0, -59.0]]\n","Agent 1: react_prev, Agent 2: counter_stats, Result: [[99.0, -99.0]]\n","Agent 1: react_prev, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: react_prev, Agent 2: one_third, Result: [[39.0, -39.0]]\n","Agent 1: cycle_order, Agent 2: counter_react_prev, Result: [[0, 0]]\n","Agent 1: cycle_order, Agent 2: counter_cycle_order, Result: [[-95.0, 95.0]]\n","Agent 1: cycle_order, Agent 2: statistical, Result: [[0, 0]]\n","Agent 1: cycle_order, Agent 2: counter_stats, Result: [[0, 0]]\n","Agent 1: cycle_order, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: cycle_order, Agent 2: one_third, Result: [[0, 0]]\n","Agent 1: counter_react_prev, Agent 2: counter_cycle_order, Result: [[-48.0, 48.0]]\n","Agent 1: counter_react_prev, Agent 2: statistical, Result: [[0, 0]]\n","Agent 1: counter_react_prev, Agent 2: counter_stats, Result: [[49.0, -49.0]]\n","Agent 1: counter_react_prev, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: counter_react_prev, Agent 2: one_third, Result: [[36.0, -36.0]]\n","Agent 1: counter_cycle_order, Agent 2: statistical, Result: [[-99.0, 99.0]]\n","Agent 1: counter_cycle_order, Agent 2: counter_stats, Result: [[-97.0, 97.0]]\n","Agent 1: counter_cycle_order, Agent 2: adaptive, Result: [[-88.0, 88.0]]\n","Agent 1: counter_cycle_order, Agent 2: one_third, Result: [[-99.0, 99.0]]\n","Agent 1: statistical, Agent 2: counter_stats, Result: [[97.0, -97.0]]\n","Agent 1: statistical, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: statistical, Agent 2: one_third, Result: [[0, 0]]\n","Agent 1: counter_stats, Agent 2: adaptive, Result: [[0, 0]]\n","Agent 1: counter_stats, Agent 2: one_third, Result: [[-96.0, 96.0]]\n","Agent 1: adaptive, Agent 2: one_third, Result: [[0, 0]]\n","Agent: rock_only, Wins: 2, Losses: 7, Draws: 3\n","Agent: paper_only, Wins: 2, Losses: 5, Draws: 5\n","Agent: scissors_only, Wins: 3, Losses: 5, Draws: 4\n","Agent: copy_opponent, Wins: 2, Losses: 4, Draws: 6\n","Agent: random_only, Wins: 0, Losses: 0, Draws: 12\n","Agent: react_prev, Wins: 8, Losses: 0, Draws: 4\n","Agent: cycle_order, Wins: 1, Losses: 1, Draws: 10\n","Agent: counter_react_prev, Wins: 5, Losses: 2, Draws: 5\n","Agent: counter_cycle_order, Wins: 2, Losses: 9, Draws: 1\n","Agent: statistical, Wins: 6, Losses: 1, Draws: 5\n","Agent: counter_stats, Wins: 2, Losses: 5, Draws: 5\n","Agent: adaptive, Wins: 2, Losses: 0, Draws: 10\n","Agent: one_third, Wins: 6, Losses: 2, Draws: 4\n"]}]},{"cell_type":"markdown","source":["Лучшие агенты\n","\n","Agent: react_prev, Wins: 8, Losses: 0, Draws: 4\n","\n","Agent: statistical, Wins: 6, Losses: 1, Draws: 5\n","\n","Agent: one_third, Wins: 6, Losses: 2, Draws: 4"],"metadata":{"id":"ofVQg6yQsGWo"}},{"cell_type":"code","source":[],"metadata":{"id":"O5tKuuXfsMmh"},"execution_count":null,"outputs":[]}]}